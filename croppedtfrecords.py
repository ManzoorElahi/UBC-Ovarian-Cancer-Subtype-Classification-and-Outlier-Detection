{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceType":"competition","sourceId":45867,"databundleVersionId":6924515},{"sourceType":"datasetVersion","sourceId":6774400,"datasetId":3895136},{"sourceType":"datasetVersion","sourceId":6984590,"datasetId":4014175}],"isInternetEnabled":true,"language":"python","sourceType":"script","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install spams-bin==2.6.4\n!pip install git+https://github.com/sebastianffx/stainlib.git\n!pip install spams==2.6.3.0\n\nimport numpy as np\nimport pandas as pd\nimport os, random, math, gc, cv2\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import GroupKFold, StratifiedKFold, KFold\nimport tensorflow as tf\nfrom tqdm import tqdm\nfrom PIL import Image\nfrom stainlib.augmentation.augmenter import HedLighterColorAugmenter\n\nSEED=8677\nrandom.seed(SEED)\nos.environ['PYTHONHASHSEED'] = str(SEED)\nnp.random.seed(SEED)\ntf.random.set_seed(SEED)\n\ndf_train = pd.read_csv('/data/train.csv')\ndf_train.head()\n\ndf_train['label'].value_counts()\n\ndf_train['is_tma'].value_counts()\n\ndf_train.shape\n\nsubtype_map = {'CC':0, 'EC':1, 'HGSC':2, 'LGSC':3, 'MC':4}\n\ndef _bytes_feature(value):\n    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n\ndef serialize_example(img, y):\n    feature = {\n        'img': _bytes_feature(img),\n        'y': _bytes_feature(y),\n    }\n    example_proto = tf.train.Example(features=tf.train.Features(feature=feature))\n    return example_proto.SerializeToString()\n\nhed_lighter_aug = HedLighterColorAugmenter()\n\n!mkdir /data/croppedtfrecords\n\nopts = tf.io.TFRecordOptions(compression_type=\"GZIP\")\nskf = StratifiedKFold(n_splits=20, random_state=42, shuffle=True)\ncount = 0\nfor fold, (train_index, test_index) in enumerate(skf.split(df_train,df_train['y'])):\n    if fold < 60:\n        image_ids = df_train['image_id'].values[test_index]\n        y_test = df_train['y'].values[test_index]\n        paths = df_train['path'].values[test_index]\n        tma_ls = df_train['is_tma'].values[test_index]\n        tfr_filename = f'/data/croppedtfrecords/ubc-ocean-2023-{fold:03}.tfrec'\n        \n        with tf.io.TFRecordWriter(tfr_filename, options=opts) as writer:\n            for img_id,y,is_tma in zip(image_ids,y_test,tma_ls):\n                \n                yoh = np.zeros(5,dtype=np.uint8)\n                yoh[y] = 1\n                \n                if is_tma:\n                    for i in [0,192,384,576,768]:\n                        img_path = f'/data/cropped/{img_id}_{i}.npy'\n                        img = np.load(img_path)\n                        hed_lighter_aug.randomize()\n                        example = serialize_example(hed_lighter_aug.transform(img).tobytes(),yoh.tobytes())\n                        writer.write(example)\n                        count += 1\n                        example = serialize_example(img.tobytes(),yoh.tobytes())\n                        writer.write(example)\n                        count += 1\n                \n                else:\n                    for i in range(5):\n\n                        img_path = f'/data/cropped/{img_id}_{i}.npy'\n                        img = np.load(img_path)\n                        hed_lighter_aug.randomize()\n                        example = serialize_example(hed_lighter_aug.transform(img).tobytes(),yoh.tobytes())\n                        writer.write(example)\n                        count += 1\n                        example = serialize_example(img.tobytes(),yoh.tobytes())\n                        writer.write(example)\n                        count += 1\n\n\nfrom os import listdir\nfrom os.path import isfile, join\n\ndir_path = '/data/noncancerous/'\nfiles = [join(dir_path, f) for f in listdir(dir_path)]\n\ntfr_filename = f'/data/croppedtfrecords/ubc-ocean-2023-nc-000.tfrec'\nyoh = np.zeros(5,dtype=np.uint8)        \nwith tf.io.TFRecordWriter(tfr_filename, options=opts) as writer:\n    for img_path in files:\n        img = np.load(img_path)\n        example = serialize_example(hed_lighter_aug.transform(img).tobytes(),yoh.tobytes())\n        writer.write(example)\n        count += 1\n        example = serialize_example(img.tobytes(),yoh.tobytes())\n        writer.write(example)\n        count += 1\n\nprint(count)","metadata":{"_uuid":"c068c8a1-95e1-4beb-8c56-95d7bee8330e","_cell_guid":"22b32837-c285-404a-a296-664a27bd1f6e","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]}]}