{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":45867,"databundleVersionId":6924515,"sourceType":"competition"},{"sourceId":6774400,"sourceType":"datasetVersion","datasetId":3895136},{"sourceId":6774553,"sourceType":"datasetVersion","datasetId":3898019},{"sourceId":154459349,"sourceType":"kernelVersion"},{"sourceId":157017716,"sourceType":"kernelVersion"}],"isInternetEnabled":false,"language":"python","sourceType":"script","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install keras-cv-attention-models==1.3.22\n\n# https://www.kaggle.com/code/jirkaborovec/cancer-subtype-lightning-torch-inference-tiles\n\n!ls /packages/pyvips-python-and-deb-package-gpu\n# intall the deb packages\n!yes | dpkg -i --force-depends /packages/pyvips-python-and-deb-package-gpu/linux_packages/archives/*.deb\n# install the python wrapper\n!pip install pyvips -f /packages/pyvips-python-and-deb-package-gpu/python_packages/ --no-index\n\nimport pyvips\nimport numpy as np\nimport pandas as pd\nimport os, random, math, gc, cv2\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import GroupKFold, StratifiedKFold, KFold\nimport tensorflow as tf\nfrom tqdm import tqdm\nfrom keras_cv_attention_models import convnext, efficientnet, hornet, beit, davit\n\nos.environ['VIPS_CONCURRENCY'] = '4'\nos.environ['VIPS_DISC_THRESHOLD'] = '15gb'\n\nSEED=8677\nrandom.seed(SEED)\nos.environ['PYTHONHASHSEED'] = str(SEED)\nnp.random.seed(SEED)\ntf.random.set_seed(SEED)\n\n# # FPN MODEL\n\ndef FPNBlock(inputs0, inputs1, output_channel, activation=\"gelu\", name=''):\n    nn0 = tf.keras.layers.Conv2D(output_channel, kernel_size=1, strides=1, padding=\"same\", name=name+'_conv2d_0')(inputs0)\n    nn1 = tf.keras.layers.Conv2D(output_channel, kernel_size=1, strides=1, padding=\"same\", name=name+'_conv2d_1')(inputs1)\n    nn1 = tf.keras.layers.UpSampling2D(2, name=name+'_up_0')(nn1)\n    nn = tf.keras.layers.Concatenate(name=name+'_merge_0')([nn0, nn1])\n    return nn\n\ndef UpBlockFinal(inputs, output_channel, activation=\"gelu\", name=''):\n    nn = tf.keras.layers.UpSampling2D(2, name=name+'_up_0')(inputs)\n    nn = tf.keras.layers.Conv2D(output_channel, kernel_size=3, strides=1, padding=\"same\", name=name+'_conv2d_0')(nn)\n    nn = tf.keras.layers.LayerNormalization(axis=-1, epsilon=1e-6, name=name+'_ln_0')(nn)\n    nn = tf.keras.layers.Activation(activation=activation, name=name+'_act_0')(nn)\n    nn = tf.keras.layers.Conv2D(output_channel, kernel_size=3, strides=1, padding=\"same\", name=name+'_conv2d_1')(nn)\n    nn = tf.keras.layers.LayerNormalization(axis=-1, epsilon=1e-6, name=name+'_ln_1')(nn)\n    nn = tf.keras.layers.Activation(activation=activation, name=name+'_act_1')(nn)\n    return nn\n\ndef ConvBlock(inputs, output_channel, activation=\"gelu\", name=''):\n    nn = tf.keras.layers.Conv2D(output_channel, kernel_size=3, strides=1, padding=\"same\", name=name+'_conv2d_0')(inputs)\n    nn = tf.keras.layers.LayerNormalization(axis=-1, epsilon=1e-6, name=name+'_ln_0')(nn)\n    nn = tf.keras.layers.Activation(activation=activation, name=name+'_act_0')(nn)\n    nn = tf.keras.layers.Conv2D(output_channel, kernel_size=3, strides=1, padding=\"same\", name=name+'_conv2d_1')(nn)\n    nn = tf.keras.layers.LayerNormalization(axis=-1, epsilon=1e-6, name=name+'_ln_1')(nn)\n    nn = tf.keras.layers.Activation(activation=activation, name=name+'_act_1')(nn)\n    return nn\n\ndef get_model_fpn(model_name='convnext', model_size='b'):\n    \n    if model_name == 'convnext':\n        \n        if model_size == 'b':\n    \n            base_layer = convnext.ConvNeXtBase(input_shape=(512,512,3), pretrained=None, \n                                               drop_connect_rate=0.1, num_classes=0)\n        else:\n            \n            base_layer = convnext.ConvNeXtSmall(input_shape=(512,512,3), pretrained=None, \n                                                drop_connect_rate=0.1, num_classes=0)\n\n        inputs = base_layer.input\n\n        nn0 = base_layer.get_layer('stack1_block1_output').output\n        nn1 = base_layer.get_layer('stack1_block3_output').output\n        nn2 = base_layer.get_layer('stack2_block3_output').output\n        nn3 = base_layer.get_layer('stack3_block27_output').output\n        nn4 = base_layer.get_layer('stack4_block3_output').output\n        \n    elif model_name == 'hornet':\n        \n        if model_size == 'b':\n            \n            base_layer = hornet.HorNetBase(input_shape=(512,512,3), pretrained=None, \n                                           drop_connect_rate=0.1, num_classes=0)\n        else:\n            \n            base_layer = hornet.HorNetSmall(input_shape=(512,512,3), pretrained=None, \n                                            drop_connect_rate=0.1, num_classes=0)\n    \n        inputs = base_layer.input\n\n        nn0 = base_layer.get_layer('stack1_block1_2_output').output\n        nn1 = base_layer.get_layer('stack1_block2_2_output').output\n        nn2 = base_layer.get_layer('stack2_block3_2_output').output\n        nn3 = base_layer.get_layer('stack3_block18_2_output').output\n        nn4 = base_layer.get_layer('stack4_block2_2_output').output\n        \n    y = nn4\n    y = tf.keras.layers.GlobalAveragePooling2D(name='global_ave')(y)\n    y = tf.keras.layers.Dropout(0.2, name='dropout')(y)\n    y = tf.keras.layers.Dense(5, dtype=\"float32\", activation='sigmoid', \n                              name='class_output')(y)\n        \n    nn0 = tf.keras.layers.UpSampling2D(2, name='up_0')(nn0)\n    nn0 = ConvBlock(nn0, 48, activation=\"gelu\", name='feat_conv_0')    \n    \n    nn3 = FPNBlock(nn3, nn4, 256, activation=\"gelu\", name='fpn3')\n    nn2 = FPNBlock(nn2, nn3, 256, activation=\"gelu\", name='fpn2')\n    nn1 = FPNBlock(nn1, nn2, 256, activation=\"gelu\", name='fpn1')\n    nn0 = FPNBlock(nn0, nn1, 256, activation=\"gelu\", name='fpn0')\n    \n    nn3 = ConvBlock(nn3, 256, activation=\"gelu\", name='convblock_3')\n    nn2 = ConvBlock(nn2, 256, activation=\"gelu\", name='convblock_2')\n    nn1 = ConvBlock(nn1, 256, activation=\"gelu\", name='convblock_1')\n    nn0 = ConvBlock(nn0, 256, activation=\"gelu\", name='convblock_0')\n    \n    nn3 = tf.keras.layers.UpSampling2D(8, name='fpn_up_3')(nn3)\n    nn2 = tf.keras.layers.UpSampling2D(4, name='fpn_up_2')(nn2)\n    nn1 = tf.keras.layers.UpSampling2D(2, name='fpn_up_1')(nn1)\n    \n    nn = tf.keras.layers.Add(name='fpn_merge_0')([nn0, nn1, nn2, nn3])\n    nn = ConvBlock(nn, 128, activation=\"gelu\", name='fpn_final')\n    \n    nn = tf.keras.layers.Conv2D(3, kernel_size=3, padding=\"same\", \n                                dtype=\"float32\", activation='sigmoid', \n                                name='mask_output')(nn)\n    \n    model = tf.keras.Model(inputs=inputs, outputs=[nn,y])\n    return model\n\n# # Mask Prediction\n\nmodel_fpn = get_model_fpn(model_name='convnext', model_size='b')\nmodel_fpn.load_weights('/weights/model_convnextbase_fpn_1_25epochs.h5')\n\ndf_train = pd.read_csv('/data/ubcocean/train.csv')\n\nsubtype_map = {'CC':0, 'EC':1, 'HGSC':2, 'LGSC':3, 'MC':4}\n\n# https://www.kaggle.com/competitions/UBC-OCEAN/discussion/445804\nbad_ids = [281, 3222, 5264, 9154, 12244, 26124, 31793, 32192, 33839, 41099, \n           52308, 54506, 63836, 1289, 32035]\ndf_train.loc[df_train.image_id == 15583,'label'] = 'MC'\ndf_train = df_train[~df_train.image_id.isin(bad_ids)].reset_index(drop=True)\n\ndf_train['y'] = df_train['label'].map(subtype_map)\ndf_train.head()\n\ndf_train.to_csv('/data/train.csv',index=False)\ndf_train.shape\n\nimport json\n\nwith open(\"/data/ubcocean/updated_image_ids.json\") as json_file:\n    json_data = json.load(json_file)\n    \nupdated_image_ids = [int(x) for x in json_data]\n\n!mkdir /data/cropped\n\nMEAN = np.array([0.485, 0.456, 0.406]).astype(np.float32).reshape((1,1,1,3))\nSTD = np.array([0.229, 0.224, 0.225]).astype(np.float32).reshape((1,1,1,3))\nTILE_SIZE = 768\nCROP_SIZE_ls = [256,512,1024,1536,2048]\ncount = np.zeros(5)\n\nfor img_id,w,h,istma,y in tqdm(zip(df_train['image_id'].values,df_train['image_width'].values,\n                                   df_train['image_height'].values,df_train['is_tma'].values,\n                                   df_train['y'].values)):\n    \n        if img_id in updated_image_ids:\n            \n            img_path = f'/data/ubcocean/train_images/{img_id}.png'\n            img = pyvips.Image.new_from_file(img_path).numpy()\n            h,w = img.shape[:2]\n            del img\n            gc.collect()\n                    \n        if istma:\n            img_path = f'/data/ubcocean/train_images/{img_id}.png'\n            img = pyvips.Image.new_from_file(img_path).numpy()\n            \n            for i in [0,192,384,576,768]:\n                img0 = img[i:img.shape[0]-i,i:img.shape[0]-i,:3]\n                img0 = cv2.resize(img0, (TILE_SIZE, TILE_SIZE), interpolation = cv2.INTER_CUBIC)\n            \n                with open(f'/data/cropped/{img_id}_{i}.npy', 'wb') as f:\n                    np.save(f, img0)\n                \n            del img, img0\n            gc.collect()\n            \n        else:\n            img_path = f'/data/ubcocean/train_thumbnails/{img_id}_thumbnail.png'\n            img = pyvips.Image.new_from_file(img_path).numpy()\n            h_tn,w_tn = img.shape[:2]\n            \n            if min(h_tn,w_tn) < 1536:\n                if h<=w:\n                    h_tn = 1536\n                    w_tn = int(w*1536/h)\n                else:\n                    w_tn = 1536\n                    h_tn = int(h*1536/w)\n                        \n                img_path = f'/data/ubcocean/train_images/{img_id}.png'\n                img = pyvips.Image.thumbnail(img_path, w_tn).numpy()[:,:,:3]\n                gc.collect()\n                    \n            if h<=w:\n                h_tn = 1536\n                w_tn = int(w*1536/h)\n            else:\n                w_tn = 1536\n                h_tn = int(h*1536/w)\n                    \n            img = cv2.resize(img, (w_tn, h_tn), interpolation = cv2.INTER_CUBIC)\n            gc.collect()\n            \n            h_tn,w_tn = img.shape[:2]\n            imgs = []\n            pos_i_ls = []\n            pos_j_ls = []\n            for i in range(0,512*(img.shape[0]//512),512):\n                for j in range(0,512*(img.shape[1]//512),512):\n                    if img[i:i+512, j:j+512,0].sum() > 15000000:\n                        pos_i_ls.append(i)\n                        pos_j_ls.append(j)\n                        imgs.append(img[i:i+512, j:j+512,:])\n\n            imgs = np.stack(imgs, axis=0)\n            imgs_ = imgs.copy()\n            imgs = imgs.astype(np.float32)/255.0\n            imgs = (imgs-MEAN)/STD\n            \n            del img\n            gc.collect()\n            \n            p0,p1 = model_fpn.predict(imgs,batch_size=4,verbose=False)\n            \n            idx0 = np.argmax(p1[:,y])\n            i_max, j_max = np.unravel_index(p0[idx0,:,:,0].argmax(), (256,256))\n            i_max = pos_i_ls[idx0]+2*i_max\n            j_max = pos_j_ls[idx0]+2*j_max\n            i_max = int(i_max*(h/h_tn))\n            j_max = int(j_max*(w/w_tn))\n                \n            if np.max(p1[:,y]) > 0.5:\n                count[y] += 1\n            \n            del imgs,p0,p1,imgs_\n            gc.collect()\n            \n            img_path = f'/data/ubcocean/train_images/{img_id}.png'\n            img = pyvips.Image.new_from_file(img_path)\n            \n            for i, CROP_SIZE in enumerate(CROP_SIZE_ls):\n                img0 = img.crop(min(max(j_max - CROP_SIZE//2,0),w-CROP_SIZE-10), \n                                min(max(i_max - CROP_SIZE//2,0),h-CROP_SIZE-10), \n                                CROP_SIZE, CROP_SIZE).numpy()[:,:,:3]\n\n                img0 = cv2.resize(img0, (TILE_SIZE, TILE_SIZE), interpolation = cv2.INTER_CUBIC)\n            \n                with open(f'/data/cropped/{img_id}_{i}.npy', 'wb') as f:\n                    np.save(f, img0)\n                \n            del img,img0\n            gc.collect()\n\nprint(count)","metadata":{"_uuid":"576a3729-48dc-4e9b-bd89-ace78b01457b","_cell_guid":"b66a8565-0c7c-4561-a69b-cd73dcaf3c2f","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]}]}