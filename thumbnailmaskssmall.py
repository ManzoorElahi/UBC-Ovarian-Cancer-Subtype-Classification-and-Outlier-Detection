{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":45867,"databundleVersionId":6924515,"sourceType":"competition"},{"sourceId":6774400,"sourceType":"datasetVersion","datasetId":3895136},{"sourceId":6984590,"sourceType":"datasetVersion","datasetId":4014175}],"isInternetEnabled":true,"language":"python","sourceType":"script","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# https://www.kaggle.com/code/jirkaborovec/cancer-subtype-cut-wsi-tiles-mask-0-25x/notebook\n\n# intall the deb packages\n!dpkg -i /packages/pyvips-python-and-deb-package/linux_packages/archives/*.deb\n# install the python wrapper\n!pip install pyvips -f /packages/pyvips-python-and-deb-package/python_packages/ --no-index\n\nimport pyvips\nimport numpy as np\nimport pandas as pd\nimport os, random, math, gc, cv2\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import GroupKFold, StratifiedKFold, KFold\nimport tensorflow as tf\nfrom tqdm import tqdm\nfrom PIL import Image\n\nos.environ['VIPS_DISC_THRESHOLD'] = '9gb'\n\nSEED=8677\nrandom.seed(SEED)\nos.environ['PYTHONHASHSEED'] = str(SEED)\nnp.random.seed(SEED)\ntf.random.set_seed(SEED)\n\ndf_train = pd.read_csv('/data/ubcocean/train.csv')\ndf_train.head()\n\ndf_train['label'].value_counts()\n\ndf_train['is_tma'].value_counts()\n\nsubtype_map = {'CC':0, 'EC':1, 'HGSC':2, 'LGSC':3, 'MC':4}\n\n# https://www.kaggle.com/competitions/UBC-OCEAN/discussion/445804\nbad_ids = [281, 3222, 5264, 9154, 12244, 26124, 31793, 32192, 33839, 41099, \n           52308, 54506, 63836, 1289, 32035]\ndf_train.loc[df_train.image_id == 15583,'label'] = 'MC'\ndf_train = df_train[~df_train.image_id.isin(bad_ids)].reset_index(drop=True)\n\nfile_names = [int(f.split('.')[0]) for f in os.listdir('/data/supplementalmasks')]\ndf_train = df_train[df_train.image_id.isin(file_names)].reset_index(drop=True)\n\ndf_train['y'] = df_train['label'].map(subtype_map)\ndf_train.head()\n\nimport json\n\nwith open(\"/data/ubcocean/updated_image_ids.json\") as json_file:\n    json_data = json.load(json_file)\n    \nupdated_image_ids = [int(x) for x in json_data]\n\ndf_train['label'].value_counts()\n\ndf_train['y'].value_counts()\n\ndf_train['is_tma'].value_counts()\n\ndf_train.shape\n\ndef _bytes_feature(value):\n    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n\ndef serialize_example(img, msk, y):\n    feature = {\n        'img': _bytes_feature(img),\n        'msk': _bytes_feature(msk),\n        'y': _bytes_feature(y),\n    }\n    example_proto = tf.train.Example(features=tf.train.Features(feature=feature))\n    return example_proto.SerializeToString()\n\n!mkdir /data/thumbnailmaskssmall\n\nTILE_SIZE = 512\ncount = 0\nopts = tf.io.TFRecordOptions(compression_type=\"GZIP\")\nkf = KFold(n_splits=25, random_state=42, shuffle=True)\n\nsmall_count = 0\n\nfor fold, (train_index, test_index) in tqdm(enumerate(kf.split(df_train))):\n    if fold < 60:\n        image_ids = df_train['image_id'].values[test_index]\n        y_test = df_train['y'].values[test_index]\n        w_test = df_train['image_width'].values[test_index]\n        h_test = df_train['image_height'].values[test_index]\n        tfr_filename = f'/data/thumbnailmaskssmall/ubc-ocean-2023-msk-{fold:03}.tfrec'\n        with tf.io.TFRecordWriter(tfr_filename, options=opts) as writer:\n            for img_id,y,w,h in zip(image_ids,y_test,w_test,h_test):\n                \n                if img_id in updated_image_ids:\n            \n                    img_path = f'/data/ubcocean/train_images/{img_id}.png'\n                    img = pyvips.Image.new_from_file(img_path).numpy()\n                    h,w = img.shape[:2]\n                    del img\n                    gc.collect()\n                \n                img_path = f'/data/ubcocean/train_thumbnails/{img_id}_thumbnail.png'\n                img = pyvips.Image.new_from_file(img_path).numpy()[:,:,:3]\n                h_tn,w_tn = img.shape[:2]\n                if min(h_tn,w_tn) < 1536:\n                    \n                    if h<=w:\n                        h_tn = 1536\n                        w_tn = int(w*1536/h)\n                    else:\n                        w_tn = 1536\n                        h_tn = int(h*1536/w)\n                        \n                    img_path = f'/data/ubcocean/train_images/{img_id}.png'\n                    img = pyvips.Image.thumbnail(img_path, w_tn).numpy()[:,:,:3]\n                    \n                    small_count += 1\n\n                msk_path = f'/data/supplementalmasks/{img_id}.png'\n                msk = pyvips.Image.thumbnail(msk_path, w_tn).numpy()[:,:,:3]\n                \n                h,w = img.shape[:2]\n                gc.collect()\n\n                for min_size in [2048,1536,1024]:\n                    \n                    if h<=w:\n                        ht = min_size\n                        wt = int(w*min_size/h)\n                    else:\n                        wt = min_size\n                        ht = int(h*min_size/w)\n\n                    img0 = cv2.resize(img, (wt, ht), interpolation = cv2.INTER_CUBIC)\n                    msk0 = cv2.resize(msk, (wt, ht), interpolation = cv2.INTER_CUBIC)\n\n\n                    for i in range(0,TILE_SIZE*(img0.shape[0]//TILE_SIZE),TILE_SIZE):\n                        for j in range(0,TILE_SIZE*(img0.shape[1]//TILE_SIZE),TILE_SIZE):\n                            \n                            yoh = np.zeros(5,dtype=np.uint8)\n\n                            if np.clip(msk0[i:i+TILE_SIZE, j:j+TILE_SIZE,:],0,1).sum() > 20:\n                                \n                                if np.clip(msk0[i:i+TILE_SIZE, j:j+TILE_SIZE,0],0,1).sum() > 10:\n                                    yoh[y] = 1\n\n                                example = serialize_example(img0[i:i+TILE_SIZE, j:j+TILE_SIZE,:].tobytes(), \n                                                            msk0[i:i+TILE_SIZE, j:j+TILE_SIZE,:].tobytes(), \n                                                            yoh.tobytes())\n                                writer.write(example)\n\n                                count += 1\n\n                    for i in range(TILE_SIZE//2,TILE_SIZE*((img0.shape[0]-TILE_SIZE//2)//TILE_SIZE),TILE_SIZE):\n                        for j in range(TILE_SIZE//2,TILE_SIZE*((img0.shape[1]-TILE_SIZE//2)//TILE_SIZE),TILE_SIZE):\n                            \n                            yoh = np.zeros(5,dtype=np.uint8)\n\n                            if np.clip(msk0[i:i+TILE_SIZE, j:j+TILE_SIZE,:],0,1).sum() > 20:\n                                \n                                if np.clip(msk0[i:i+TILE_SIZE, j:j+TILE_SIZE,0],0,1).sum() > 10:\n                                    yoh[y] = 1\n\n                                example = serialize_example(img0[i:i+TILE_SIZE, j:j+TILE_SIZE,:].tobytes(), \n                                                            msk0[i:i+TILE_SIZE, j:j+TILE_SIZE,:].tobytes(), \n                                                            yoh.tobytes())\n                                writer.write(example)\n\n                                count += 1\n\ncount","metadata":{"_uuid":"e0c79cea-7af7-4c04-bc21-d02605412c56","_cell_guid":"35eede36-8554-4c8d-90a2-3bcaea806736","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]}]}